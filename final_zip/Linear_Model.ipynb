{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Neural Networks to ecotoxicological data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and prepare data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "genpath = 'D:/Code'\n",
    "if genpath not in sys.path:\n",
    "    sys.path.append(genpath)\n",
    "\n",
    "import DataSciPy\n",
    "from sklearn.linear_model import Perceptron\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import src.general_helper as genH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data set and split the `fingerprint`-column to one column for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['test_cas', 'species', 'conc1_type', 'exposure_type',\n",
      "       'obs_duration_mean', 'conc1_mean', 'class', 'tax_order', 'family',\n",
      "       'genus', 'fingerprint'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "final_db = pd.read_csv('data/processed/final_db_update.csv')\n",
    "print(final_db.columns)\n",
    "fp = pd.DataFrame(final_db.fingerprint.apply(genH.splt_str))\n",
    "fp = pd.DataFrame(fp.fingerprint.tolist(), index=fp.index)\n",
    "final_db = final_db.drop(columns=['fingerprint']).join(fp).drop(columns=['test_cas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8566 datapoints with label 0 and 14761 datapoints with label 1\n",
      "(16328, 889)\n"
     ]
    }
   ],
   "source": [
    "# These are the names of the columns that should be encoded\n",
    "encode_these = ['species','conc1_type','exposure_type','class','tax_order',\n",
    "                'family','genus','obs_duration_mean']\n",
    "final_db = genH.binary_score(final_db)\n",
    "dummy = DataSciPy.Dataset()\n",
    "dummy.setup_data(X=final_db.drop(columns=['score']),\n",
    "                 y=final_db.loc[:,['score']],\n",
    "                 split_test=0.3)\n",
    "dummy.encode_categories(variables=encode_these)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit perceptron to obtain a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39005572224603513"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(tol=1e-3, random_state=0)\n",
    "per.fit(dummy.X_train, dummy.y_train.iloc[:,0])\n",
    "per.score(dummy.X_test, dummy.y_test.iloc[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
